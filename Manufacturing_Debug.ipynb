{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))\n",
    "import openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import videoHtml\n",
    "# videoHtml.videoHTML('Manufacturing', ['original_videos/Manufacturing.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/data/models/intel/person-detection-retail-0013/FP16/person-detection-retail-0013'\n",
    "VIDEO = '/data/resources/manufacturing.mp4'\n",
    "QUEUE = '/data/queue_param/manufacturing.npy'\n",
    "PEOPLE = 5\n",
    "\n",
    "\n",
    "def submit(device, node):\n",
    "    device_postfix = device\n",
    "    if device.startswith('HETERO:FPGA'):\n",
    "        device_postfix = 'FPGA'\n",
    "        \n",
    "    job_name = 'JOB_MANUFACTURING_' + device_postfix\n",
    "    output = '/output/results/manufacturing/' + device_postfix\n",
    "    params = '{} {} {} {} {} {}'.format(MODEL_PATH, device, VIDEO, QUEUE, output, PEOPLE)\n",
    "\n",
    "    job_id = !qsub queue_job.sh -l nodes=1:{node} -d . -F \"{params}\" -N {job_name}\n",
    "    return job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:mHBOwLVSUGBoFdSYHl38N0BjpRKsyLda) are ready.\n",
      "Please wait....Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n",
      "Could not run Inference:  too many values to unpack (expected 2)\n",
      "results/\n",
      "results/manufacturing/\n",
      "results/manufacturing/output_video.mp4\n",
      "stderr.log\n",
      "Traceback (most recent call last):\n",
      "  File \"person_detect.py\", line 204, in main\n",
      "    coords, image = pd.predict(frame)\n",
      "  File \"person_detect.py\", line 113, in predict\n",
      "    bounding_boxes, output_image = self.draw_outputs(bb_xy, image)\n",
      "ValueError: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "# cpu_job_id = submit('CPU', 'tank-870:i5-6500te')\n",
    "\n",
    "# print(cpu_job_id[0])\n",
    "\n",
    "cpu_job_id = !qsub queue_job.sh -d . -l \"nodes=1:tank-870:i5-6500te\" -F \"/data/models/intel/person-detection-retail-0013/FP16/person-detection-retail-0013 CPU /data/resources/manufacturing.mp4 /data/queue_param/manufacturing.npy /output/results/manufacturing/ 2\" -N store_core\n",
    "\n",
    "import liveQStat\n",
    "liveQStat.liveQStat()\n",
    "\n",
    "import get_results\n",
    "get_results.getResults(cpu_job_id[0], filename='output.tgz', blocking=True)\n",
    "\n",
    "!tar zxf output.tgz\n",
    "!cat stdout.log\n",
    "!cat stderr.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device_list=['CPU', 'GPU', 'FPGA', 'MYRIAD']\n",
    "inference_time=[]\n",
    "fps=[]\n",
    "model_load_time=[]\n",
    "\n",
    "for device in device_list:\n",
    "    with open('results/manufacturing/'+device+'/stats.txt', 'r') as f:\n",
    "        inference_time.append(float(f.readline().split(\"\\n\")[0]))\n",
    "        fps.append(float(f.readline().split(\"\\n\")[0]))\n",
    "        model_load_time.append(float(f.readline().split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(device_list, inference_time)\n",
    "plt.xlabel(\"Device Used\")\n",
    "plt.ylabel(\"Total Inference Time in Seconds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(device_list, fps)\n",
    "plt.xlabel(\"Device Used\")\n",
    "plt.ylabel(\"Frames per Second\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(device_list, model_load_time)\n",
    "plt.xlabel(\"Device Used\")\n",
    "plt.ylabel(\"Model Loading Time in Seconds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'| Device\\t | Inference Time(s)\\t | FPS\\t\\t | Load Time(s)\\t |')\n",
    "print(f'|----------------|-----------------------|---------------|---------------|')\n",
    "for i,d in enumerate(device_list):\n",
    "    print(f'| {device_list[i]}   \\t | {inference_time[i]}\\t\\t\\t | {fps[i]:.3f}\\t | {model_load_time[i]:.3f}\\t |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "p = fig.add_subplot(111)\n",
    "\n",
    "width = 0.2\n",
    "x = np.arange(len(device_list))\n",
    "y1 = p.bar(x, inference_time, width=0.2, color='r', align='center')\n",
    "y2 = p.bar(x + width, model_load_time, width=0.2, color='b', align='center')\n",
    "# p.bar(x + width*2, fps, width=0.2, color='g', align='center')\n",
    "\n",
    "p.set_ylabel('Seconds')\n",
    "p.set_xticks(x + width/2)\n",
    "p.set_xticklabels(device_list)\n",
    "p.legend( (y1[0], y2[0]), ('Inference Time', 'Model Load Time') )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
