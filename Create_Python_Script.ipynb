{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Create the Python Script\n",
    "\n",
    "In the cell below, you will need to complete the Python script and run the cell to generate the file using the magic `%%writefile` command. Your main task is to complete the following methods for the `PersonDetect` class:\n",
    "* `load_model`\n",
    "* `predict`\n",
    "* `draw_outputs`\n",
    "* `preprocess_outputs`\n",
    "* `preprocess_inputs`\n",
    "\n",
    "For your reference, here are all the arguments used for the argument parser in the command line:\n",
    "* `--model`:  The file path of the pre-trained IR model, which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware.\n",
    "* `--device`: The type of hardware you want to load the model on (CPU, GPU, MYRIAD, HETERO:FPGA,CPU)\n",
    "* `--video`: The file path of the input video.\n",
    "* `--output_path`: The location where the output stats and video file with inference needs to be stored (results/[device]).\n",
    "* `--max_people`: The max number of people in queue before directing a person to another queue.\n",
    "* `--threshold`: The probability threshold value for the person detection. Optional arg; default value is 0.60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile person_detect.py\n",
    "\n",
    "\"\"\"\n",
    "Intel Edge AI for IoT Developers Nanodegree\n",
    "Project 2: Smart Queue Monitoring System\n",
    "\n",
    "person_detect.py\n",
    "\n",
    "By James D. Bartlett III\n",
    "    https://jdbartlett.net\n",
    "    https://github.com/JamesDBartlett\n",
    "    https://linkedin.com/in/JamesDBartlett3\n",
    "    Twitter: @jamesdbartlett3\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import traceback\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore\n",
    "\n",
    "\n",
    "def layer_support_checker(core, net, dev):\n",
    "    \"\"\"\n",
    "    Check if all layers in the given network are supported\n",
    "    on the given device and return the answer as boolean value\n",
    "    \"\"\"\n",
    "    all_layers = net.layers.keys()\n",
    "    supported_layers = core.query_nework(net, dev)\n",
    "    return_value = True\n",
    "    for l in all_layers:\n",
    "        if l not in supported_layers:\n",
    "            return_value = False\n",
    "            print(dev, \"does not support Layer\", l, \":-(\")\n",
    "    if return_value:\n",
    "        print(dev, \" supports all layers for this model!\")\n",
    "    return return_value\n",
    "\n",
    "\n",
    "class Queue:\n",
    "    \"\"\"\n",
    "    Class for dealing with queues\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.queues = []\n",
    "\n",
    "    # Points in the frame where the queues should be\n",
    "    def add_queue(self, points):\n",
    "        self.queues.append(points)\n",
    "\n",
    "    # Get bounding area of queues based on the queue points\n",
    "    def get_queues(self, image):\n",
    "        for q in self.queues:\n",
    "            x_min, y_min, x_max, y_max = q\n",
    "            frame = image[y_min:y_max, x_min:x_max]\n",
    "            yield frame\n",
    "\n",
    "    # Check if incoming coordinates are within the queue\n",
    "    def check_coords(self, coords):\n",
    "        d = {k + 1: 0 for k in range(len(self.queues))}\n",
    "        for coord in coords:\n",
    "            for i, q in enumerate(self.queues):\n",
    "                if coord[0] > q[0] and coord[2] < q[2]:\n",
    "                    d[i + 1] += 1\n",
    "        return d\n",
    "\n",
    "\n",
    "class PersonDetect:\n",
    "    \"\"\"\n",
    "    Class for the Person Detection Model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup colors for drawing bounding boxes and text on output image\n",
    "    a_red = [0, 0, 185]\n",
    "    a_green = [0, 185, 0]\n",
    "    a_blue = [185, 0, 0]\n",
    "    a_magenta = [185, 0, 245]\n",
    "    l_red = list(a_red)\n",
    "    l_green = list(a_green)\n",
    "    l_blue = list(a_blue)\n",
    "    l_magenta = list(a_magenta)\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        self.core = IECore()\n",
    "        self.model_weights = model_name + \".bin\"\n",
    "        self.model_structure = model_name + \".xml\"\n",
    "        self.device = device\n",
    "        self.threshold = threshold\n",
    "\n",
    "        try:\n",
    "            # Create IENetwork object from IR model\n",
    "            self.model = self.core.read_network(\n",
    "                self.model_structure, self.model_weights\n",
    "            )\n",
    "        except Exception:\n",
    "            raise ValueError(\n",
    "                \"Could not Initialise the network. Have you enterred the correct model path?\"\n",
    "            )\n",
    "\n",
    "        self.input_name = next(iter(self.model.inputs))\n",
    "        self.input_shape = self.model.inputs[self.input_name].shape\n",
    "        self.output_name = next(iter(self.model.outputs))\n",
    "        self.output_shape = self.model.outputs[self.output_name].shape\n",
    "        self.net = None\n",
    "\n",
    "    # Load the model\n",
    "    def load_model(self, device):\n",
    "        layer_support_checker(self.core, self.model, self.device)\n",
    "        self.network = self.core.load_network(self.model, self.device, 1)\n",
    "\n",
    "    # Get frame, run inference, return boxes with detected people\n",
    "    def predict(self, image):\n",
    "        _input = self.preprocess_input(image)\n",
    "        _name = self.input_name\n",
    "        start_time = time.time()\n",
    "        request = self.network.start_async(request_id=0, inputs={_name: _input})\n",
    "        if request.wait() == 0:\n",
    "            inf_time = time.time() - start_time\n",
    "            outs = request.outputs[self.output_name]\n",
    "            bb_xy = self.preprocess_outputs(outs, image)\n",
    "            bounding_boxes, output_image = self.draw_outputs(bb_xy, image)\n",
    "            timer_text = \"Inference Time: {:.2f} milliseconds\".format(inf_time / 0.001)\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                timer_text,\n",
    "                (30, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                self.l_blue,\n",
    "                2,\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        return bounding_boxes, output_image\n",
    "\n",
    "    def draw_outputs(self, coords, image):\n",
    "        copy = image.copy()\n",
    "        for c in coords:\n",
    "            cv2.rectangle(copy, c[:2], c[2:], self.l_green, 1)\n",
    "        return copy\n",
    "\n",
    "    def preprocess_outputs(self, outputs, image):\n",
    "        h, w = image.shape[:2]\n",
    "        coords = []\n",
    "        for b in outputs[0][0]:\n",
    "            if b[2] >= self.threshold:\n",
    "                xmin = int(b[3] * w)\n",
    "                ymin = int(b[4] * h)\n",
    "                xmax = int(b[5] * w)\n",
    "                ymax = int(b[6] * h)\n",
    "                coords.append((xmin, ymin, xmax, ymax))\n",
    "        return coords\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        a, b, h, w = self.input_shape\n",
    "        resized_img = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
    "        transposed_img = resized_img.transpose((2, 0, 1))\n",
    "        output_img = transposed_img.reshape(a, b, h, w)\n",
    "        return output_img\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    model = args.model\n",
    "    device = args.device\n",
    "    video_file = args.video\n",
    "    max_people = args.max_people\n",
    "    threshold = args.threshold\n",
    "    output_path = args.output_path\n",
    "\n",
    "    start_model_load_time = time.time()\n",
    "    pd = PersonDetect(model, device, threshold)\n",
    "    pd.load_model(device)\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "\n",
    "    queue = Queue()\n",
    "\n",
    "    try:\n",
    "        queue_param = np.load(args.queue_param)\n",
    "        for q in queue_param:\n",
    "            queue.add_queue(q)\n",
    "    except Exception:\n",
    "        print(\"error loading queue param file\")\n",
    "\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Cannot locate video file: \" + video_file)\n",
    "    except Exception as e:\n",
    "        print(\"Something else went wrong with the video file: \", e)\n",
    "\n",
    "    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out_video = cv2.VideoWriter(\n",
    "        os.path.join(output_path, \"output_video.mp4\"),\n",
    "        cv2.VideoWriter_fourcc(*\"avc1\"),\n",
    "        fps,\n",
    "        (initial_w, initial_h),\n",
    "        True,\n",
    "    )\n",
    "\n",
    "    counter = 0\n",
    "    start_inference_time = time.time()\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            counter += 1\n",
    "\n",
    "            coords, image = pd.predict(frame)\n",
    "            num_people = queue.check_coords(coords)\n",
    "            print(f\"Total People in frame = {len(coords)}\")\n",
    "            print(f\"Number of people in queue = {num_people}\")\n",
    "            out_text = \"\"\n",
    "            y_pixel = 25\n",
    "\n",
    "            for k, v in num_people.items():\n",
    "                out_text += f\"No. of People in Queue {k} is {v} \"\n",
    "                if v >= int(max_people):\n",
    "                    out_text += f\" Queue full; Please move to next Queue \"\n",
    "                cv2.putText(\n",
    "                    image,\n",
    "                    out_text,\n",
    "                    (15, y_pixel),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "                out_text = \"\"\n",
    "                y_pixel += 40\n",
    "            out_video.write(image)\n",
    "\n",
    "        total_time = time.time() - start_inference_time\n",
    "        total_inference_time = round(total_time, 1)\n",
    "        fps = counter / total_inference_time\n",
    "\n",
    "        with open(os.path.join(output_path, \"stats.txt\"), \"w\") as f:\n",
    "            f.write(str(total_inference_time) + \"\\n\")\n",
    "            f.write(str(fps) + \"\\n\")\n",
    "            f.write(str(total_model_load_time) + \"\\n\")\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(\"Could not run Inference: \", e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model\", required=True)\n",
    "    parser.add_argument(\"--device\", default=\"CPU\")\n",
    "    parser.add_argument(\"--video\", default=None)\n",
    "    parser.add_argument(\"--queue_param\", default=None)\n",
    "    parser.add_argument(\"--output_path\", default=\"/results\")\n",
    "    parser.add_argument(\"--max_people\", default=2)\n",
    "    parser.add_argument(\"--threshold\", default=0.60)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "Now that you've run the above cell and created your Python script, you will create your job submission shell script in the next workspace.\n",
    "\n",
    "**Note**: As a reminder, if you need to make any changes to the Python script, you can come back to this workspace to edit and run the above cell to overwrite the file with your changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
